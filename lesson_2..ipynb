{
  "metadata": {
    "name": "lesson_2",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Для упражнений сгрененирован большой набор синтетических данных в таблице `hw2.events_full`. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера.\n\nОтветить на вопросы:\n * какова структура таблиц\n * сколько в них записей \n * сколько места занимают данные\n "
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nevents_full \u003d spark.table(\"hw2.events_full\")\nsample \u003d spark.table(\"hw2.sample\")\nsample_small \u003d spark.table(\"hw2.sample_small\")\nsample_big \u003d spark.table(\"hw2.sample_big\")\nsample_very_big \u003d spark.table(\"hw2.sample_very_big\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample\\\"\")\n\nprint(\"Schema:\")\nsample.printSchema()\n\nprint(\"Rows count:\")\nprint(sample.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample\")\\\n    .filter(col(\"col_name\") \u003d\u003d \"Statistics\")\\\n    .show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample_small\\\"\")\n\nprint(\"Schema:\")\nsample_small.printSchema()\n\nprint(\"Rows count:\")\nprint(sample_small.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample_small COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample_small\")\\\n    .filter(col(\"col_name\") \u003d\u003d \"Statistics\")\\\n    .show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample_big\\\"\")\n\nprint(\"Schema:\")\nsample_big.printSchema()\n\nprint(\"Rows count:\")\nprint(sample_big.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample_big COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample_big\")\\\n    .filter(col(\"col_name\") \u003d\u003d \"Statistics\")\\\n    .show()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample_very_big\\\"\")\n\nprint(\"Schema:\")\nsample_very_big.printSchema()\n\nprint(\"Rows count:\")\nprint(sample_very_big.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample_very_big COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample_very_big\")\\\n    .filter(col(\"col_name\") \u003d\u003d \"Statistics\")\\\n    .show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Получить планы запросов для джойна большой таблицы `hw2.events_full` с каждой из таблиц `hw2.sample`, `hw2.sample_big`, `hw2.sample_very_big` по полю `event_id`. \nВ каких случаях используется **BroadcastHashJoin**? \n\n**BroadcastHashJoin** автоматически выполняется для джойна с таблицами, размером меньше параметра `spark.sql.autoBroadcastJoinThreshold`. \nУзнать его значение можно командой `spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")`."
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nspark.conf.get(\u0027spark.sql.autoBroadcastJoinThreshold\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nevents_full.join(sample, \"event_id\").explain()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nevents_full.join(sample_small, \"event_id\").explain()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nevents_full.join(sample_big, \"event_id\").explain()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nevents_full.join(sample_very_big, \"event_id\").explain()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Выполнить джойны с таблицами  `hw2.sample`,  `hw2.sample_big` в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать `.count()` для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении\n\nЗайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?  "
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nevents_full.join(sample, \"event_id\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nevents_full.join(sample_big, \"event_id\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"185.241.193.174:8088/proxy/\" + sc.applicationId + \"/jobs/\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "* Для джойна с таблицей `hw2.sample` было создано 195 tasks. Время выполнения 2 минуты.\n* Для джойна с таблицей `hw2.sample_big` было создано 397 tasks. Время выполнения - больше 10 минут. До конца так и не получилось дождаться - большая часть tasks фэйлится.\n* Посмотрел DAG-визуализацию"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Оптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится "
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import broadcast\n\nevents_full.join(broadcast(sample), \"event_id\").count()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Отключить автоматический броадкаст командой `spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")`. Сделать джойн с семплом `hw2.sample`, сравнить время выполнения запроса.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nevents_full.join(sample, \"event_id\").count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "После отключения автоматического броадкаста джоин с таблицей `hw22.sample` занял 2мин 22 сек - на 22 секунды больше\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.sql(\"clear cache\")"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.stop"
    }
  ]
}