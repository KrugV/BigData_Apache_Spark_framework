{
  "metadata": {
    "name": "lesson_4",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "* построить распределение статей в датасете по `rating` с `bin_size \u003d 10`\n* написать функцию `ratingToClass(rating: Int): String`, которая определяет категорию статьи (A, B, C, D) на основе рейтинга. Границы для классов подобрать самостоятельно.\n* добавить к датасету категориальную фичу `rating_class`. При добавлении колонки использовать `udf` из функции в предыдущем пункте\n* построить модель логистической регрессии `one vs all` для классификации статей по рассчитанным классам.\n* получить `F1 score` для получившейся модели"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import IntegerType\n\nhabrData \u003d spark.read.option(\"header\", True)\\\n.option(\"inferSchema\", True)\\\n.csv(\"/user/admin/habr_data.csv\")\\\n.withColumn(\"rating\", col(\"rating\").cast(IntegerType()))\\\n.cache()\n\nhabrData.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(habrData)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    habrData.orderBy(col(\"rating\")).groupBy(\"rating\").count().select(\"rating\", \"count\")\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import round\n\nz.show(\n    habrData\\\n        .withColumn(\"rating_10\", round(col(\"rating\") / 10) * 10)\\\n        .orderBy(\"rating_10\")\\\n        .groupBy(\"rating_10\")\\\n        .count()\\\n        .select(\"rating_10\", \"count\")\\\n        .where(col(\"rating_10\").isNotNull())\n)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import udf, col\n\ndef ratingToClass(rating):\n    article_class \u003d \u00271\u0027\n    if rating \u003e 40: \n        article_class \u003d \u00274\u0027\n    elif rating \u003e 20:\n        article_class \u003d \u00273\u0027\n    elif rating \u003e\u003d10:\n        article_class \u003d \u00272\u0027\n    elif rating \u003e\u003d 0:\n        article_class \u003d \u00271\u0027\n        \n    return article_class\n    \nrating_class \u003d udf(ratingToClass)\n\nhabrDataWithClass \u003d habrData.withColumn(\"class\", rating_class(col(\"rating\")))\n\nhabrDataWithClass.select(\"title\", \"rating\", \"class\").show(20, False)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    habrDataWithClass \\\n        .groupBy(\"class\").count() \\\n        .select(\"class\", \"count\")\n        .orderBy(\"class\")\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntrainDF, testDF \u003d habrDataWithClass.randomSplit([.8, .2], seed\u003d42)\n\ntrainDF.coalesce(2).write.mode(\"overwrite\").saveAsTable(\"habr.train\")\ntestDF.coalesce(2).write.mode(\"overwrite\").saveAsTable(\"habr.test\")\n\nprint(\"В обучающей выборке \" + str(trainDF.count()) + \" строк, в тестовой \" + str(testDF.count()) + \" строк\")"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.feature import RegexTokenizer, HashingTF, IDF\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, OneVsRest\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ntrain \u003d spark.table(\"habr.train\").selectExpr(\"description\", \"cast(class as Long) class\").na.drop(\"any\")\ntest \u003d spark.table(\"habr.test\").selectExpr(\"description\", \"cast(class as Long) class\").na.drop(\"any\")\n\nregexTokenizer \u003d RegexTokenizer(inputCol\u003d\"description\", outputCol\u003d\"description_words\", pattern\u003d\"[^a-zа-яё]\", gaps\u003dTrue).setMinTokenLength(3)\nregexTokenized \u003d regexTokenizer.transform(train)\n\nhashingTF \u003d HashingTF(inputCol\u003d\"description_words\", outputCol\u003d\"rawFeatures\", numFeatures\u003d200000)\nfeaturizedData \u003d hashingTF.transform(regexTokenized)\n\nidf \u003d IDF(inputCol\u003d\"rawFeatures\", outputCol\u003d\"features\")\nidfModel \u003d idf.fit(featurizedData)\nrescaledData \u003d idfModel.transform(featurizedData)\n\nlr \u003d LogisticRegression(labelCol\u003d\"class\", featuresCol\u003d\"features\")\novr \u003d OneVsRest(classifier\u003dlr, labelCol\u003d\"class\", featuresCol\u003d\"features\")\n\npipeline \u003d Pipeline(stages\u003d[regexTokenizer, hashingTF, idf, ovr])\nmodel \u003d pipeline.fit(train)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npredictions  \u003d model.transform(test)\nresult.select(\"prediction\", \"class\").show(20, True)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\npredictions  \u003d model.transform(test)\n\nevaluator \u003d MulticlassClassificationEvaluator(metricName\u003d\"f1\", labelCol\u003d\"class\")\nf1Score \u003d evaluator.evaluate(predictions)\nprint(\"F1 Score: \")\nprint(f1Score)"
    }
  ]
}